# RAG Pipeline System - Proper Architecture

## üéØ System Overview

This is a **3-component RAG pipeline system**:
1. **Document Vectorization Service** (Supabase trigger ‚Üí embeddings)
2. **Insights Generation Pipeline** (embeddings ‚Üí AI insights ‚Üí Supabase)
3. **RAG Chat Agent** (Next.js frontend + RAG backend)

## üèóÔ∏è Recommended Structure

```
rag-pipeline-system/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ docker-compose.yml          # Orchestrate all services
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .gitignore
‚îÇ
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ vectorization/          # Service 1: Document ‚Üí Embeddings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py        # FastAPI webhook endpoint
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vectorizer.py  # Embedding generation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ supabase_client.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ insights/               # Service 2: Embeddings ‚Üí Insights
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py        # Scheduled/triggered service
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ insights_generator.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding_analyzer.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ supabase_client.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ rag-chat/              # Service 3: RAG Chat API
‚îÇ       ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ       ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ       ‚îú‚îÄ‚îÄ src/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ main.py        # FastAPI chat endpoints
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ rag_agent.py   # Main chat agent
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ retrieval/
‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vector_search.py
‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hybrid_search.py
‚îÇ       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ context_builder.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ chat/
‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conversation_manager.py
‚îÇ       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ response_generator.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ tools/
‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ search_tools.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îÇ       ‚îî‚îÄ‚îÄ tests/
‚îÇ
‚îú‚îÄ‚îÄ shared/                     # Shared utilities across services
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ supabase/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py          # Common Supabase connection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py          # Pydantic models for tables
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schema.sql         # Database schema
‚îÇ   ‚îú‚îÄ‚îÄ ai/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ providers.py       # LLM providers (OpenAI, etc.)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ embeddings.py      # Embedding utilities
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ logging.py
‚îÇ       ‚îî‚îÄ‚îÄ config.py
‚îÇ
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îú‚îÄ‚îÄ supabase/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ migrations/        # Database migrations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ functions/         # Edge functions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ triggers/          # Database triggers
‚îÇ   ‚îú‚îÄ‚îÄ deployment/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ railway.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fly.toml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ k8s/              # If using Kubernetes
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/
‚îÇ       ‚îú‚îÄ‚îÄ health_checks.py
‚îÇ       ‚îî‚îÄ‚îÄ metrics.py
‚îÇ
‚îú‚îÄ‚îÄ scripts/                    # Deployment & maintenance scripts
‚îÇ   ‚îú‚îÄ‚îÄ deploy.py
‚îÇ   ‚îú‚îÄ‚îÄ setup_database.py
‚îÇ   ‚îú‚îÄ‚îÄ migrate.py
‚îÇ   ‚îî‚îÄ‚îÄ test_pipeline.py
‚îÇ
‚îú‚îÄ‚îÄ tests/                      # Integration tests
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py
‚îÇ   ‚îú‚îÄ‚îÄ test_pipeline_integration.py
‚îÇ   ‚îú‚îÄ‚îÄ test_vectorization_flow.py
‚îÇ   ‚îú‚îÄ‚îÄ test_insights_flow.py
‚îÇ   ‚îî‚îÄ‚îÄ test_rag_chat_flow.py
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ architecture.md
‚îÇ   ‚îú‚îÄ‚îÄ deployment.md
‚îÇ   ‚îú‚îÄ‚îÄ api-reference.md
‚îÇ   ‚îî‚îÄ‚îÄ development.md
‚îÇ
‚îî‚îÄ‚îÄ frontend-integration/       # Next.js integration helpers
    ‚îú‚îÄ‚îÄ types/
    ‚îÇ   ‚îú‚îÄ‚îÄ supabase.ts        # Generated types
    ‚îÇ   ‚îî‚îÄ‚îÄ insights.ts        # Insights types
    ‚îú‚îÄ‚îÄ api/
    ‚îÇ   ‚îú‚îÄ‚îÄ chat-client.ts     # RAG chat client
    ‚îÇ   ‚îî‚îÄ‚îÄ insights-client.ts # Insights fetching
    ‚îî‚îÄ‚îÄ components/
        ‚îú‚îÄ‚îÄ chat-interface.tsx
        ‚îî‚îÄ‚îÄ insights-display.tsx
```

## üîÑ Data Flow Architecture

```mermaid
graph LR
    A[Next.js App] -->|Document Upload| B[Supabase Documents Table]
    B -->|Database Trigger| C[Vectorization Service]
    C -->|Store Embeddings| D[Supabase Embeddings Table]
    D -->|Trigger/Schedule| E[Insights Service]
    E -->|Store Insights| F[Supabase AI_Insights Table]
    F -->|Display| A
    A -->|Chat Query| G[RAG Chat Service]
    G -->|Vector Search| D
    G -->|Response| A
```

## üöÄ Service Breakdown

### 1. Vectorization Service
**Purpose**: Convert new documents to embeddings
```python
# services/vectorization/src/main.py
from fastapi import FastAPI
from .vectorizer import DocumentVectorizer
from .supabase_client import SupabaseClient

app = FastAPI()

@app.post("/webhook/vectorize")
async def vectorize_document(payload: dict):
    # Triggered by Supabase when new document added
    doc_id = payload["record"]["id"]
    content = payload["record"]["content"]
    
    # Generate embeddings
    embeddings = await DocumentVectorizer.create_embeddings(content)
    
    # Store in Supabase
    await SupabaseClient.store_embeddings(doc_id, embeddings)
    
    return {"status": "vectorized", "doc_id": doc_id}
```

### 2. Insights Generation Service
**Purpose**: Analyze embeddings to create project insights
```python
# services/insights/src/main.py
from fastapi import FastAPI
from .insights_generator import InsightsGenerator

app = FastAPI()

@app.post("/generate-insights")
async def generate_project_insights(project_id: str):
    # Fetch related embeddings
    embeddings = await fetch_project_embeddings(project_id)
    
    # Generate insights using AI
    insights = await InsightsGenerator.analyze_embeddings(embeddings)
    
    # Store in ai_insights table
    await store_insights(project_id, insights)
    
    return {"status": "completed", "insights_count": len(insights)}
```

### 3. RAG Chat Service
**Purpose**: Provide conversational AI with document context
```python
# services/rag-chat/src/main.py
from fastapi import FastAPI
from .rag_agent import RAGAgent

app = FastAPI()

@app.post("/chat")
async def chat_endpoint(query: str, context: dict):
    # Retrieve relevant documents
    relevant_docs = await RAGAgent.retrieve_context(query)
    
    # Generate response with context
    response = await RAGAgent.generate_response(query, relevant_docs)
    
    return {"response": response, "sources": relevant_docs}
```

## üîß Configuration Strategy

### Environment Variables by Service
```bash
# Vectorization Service
SUPABASE_URL=
SUPABASE_ANON_KEY=
OPENAI_API_KEY=
EMBEDDING_MODEL=text-embedding-3-small

# Insights Service  
SUPABASE_URL=
SUPABASE_SERVICE_KEY=  # Needs write access
OPENAI_API_KEY=
INSIGHTS_MODEL=gpt-4

# RAG Chat Service
SUPABASE_URL=
SUPABASE_ANON_KEY=
OPENAI_API_KEY=
CHAT_MODEL=gpt-4-turbo
```

## üì¶ Deployment Strategy

### Option 1: Microservices (Recommended)
- Deploy each service independently
- Use Railway/Fly.io for individual services
- Scale services based on load

### Option 2: Monolith with Separation
- Single deployment with internal service separation
- Easier for small teams
- Still maintains clean architecture

## üóÑÔ∏è Supabase Integration

### Required Tables
```sql
-- Documents table (existing)
CREATE TABLE documents (
    id UUID PRIMARY KEY,
    content TEXT,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Embeddings table
CREATE TABLE document_embeddings (
    id UUID PRIMARY KEY,
    document_id UUID REFERENCES documents(id),
    chunk_index INTEGER,
    embedding VECTOR(1536),
    content TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);

-- AI Insights table  
CREATE TABLE ai_insights (
    id UUID PRIMARY KEY,
    project_id UUID,
    insight_type TEXT,
    content TEXT,
    confidence FLOAT,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);
```

### Database Triggers
```sql
-- Trigger vectorization on new documents
CREATE OR REPLACE FUNCTION trigger_vectorization()
RETURNS TRIGGER AS $$
BEGIN
    -- Call vectorization webhook
    PERFORM net.http_post(
        'https://your-vectorization-service.com/webhook/vectorize',
        '{"record": ' || row_to_json(NEW) || '}'::jsonb
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER vectorize_new_documents
    AFTER INSERT ON documents
    FOR EACH ROW
    EXECUTE FUNCTION trigger_vectorization();
```

## ‚úÖ Migration from Current Structure

1. **Extract Services**: Move related functionality to service directories
2. **Shared Code**: Extract common utilities to `shared/`
3. **Frontend Integration**: Move Next.js components to `frontend-integration/`
4. **Infrastructure**: Consolidate deployment configs
5. **Testing**: Organize by service + integration tests

This structure properly reflects your RAG pipeline requirements while maintaining clean separation between vectorization, insights generation, and chat functionality.